{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6QmWWUTFRnP",
    "outputId": "3d0b26de-1289-46f0-e38a-34c2885d2585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Farama-Foundation/MAgent2\n",
      "  Cloning https://github.com/Farama-Foundation/MAgent2 to /tmp/pip-req-build-v5xrgbq0\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Farama-Foundation/MAgent2 /tmp/pip-req-build-v5xrgbq0\n",
      "  Resolved https://github.com/Farama-Foundation/MAgent2 to commit b2ddd49445368cf85d4d4e1edcddae2e28aa1406\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy<2.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3) (1.26.4)\n",
      "Requirement already satisfied: pygame>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3) (2.6.1)\n",
      "Collecting pettingzoo>=1.23.1 (from magent2==0.3.3)\n",
      "  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting gymnasium>=0.28.0 (from pettingzoo>=1.23.1->magent2==0.3.3)\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Downloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Building wheels for collected packages: magent2\n",
      "  Building wheel for magent2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for magent2: filename=magent2-0.3.3-cp310-cp310-linux_x86_64.whl size=1696119 sha256=eee7efa0078fb7e4d237ff2fe6cf48d2a797002857b34a2e85ab18f4c0208330\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-h69s3bnh/wheels/e4/8e/bf/51a30bc4038546e23b81c9fb513fe6a8fd916e5a9c5f4291d5\n",
      "Successfully built magent2\n",
      "Installing collected packages: farama-notifications, gymnasium, pettingzoo, magent2\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 magent2-0.3.3 pettingzoo-1.24.3\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Farama-Foundation/MAgent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sD3tBzdZY-6k",
    "outputId": "a18582e7-22a4-4f66-8bae-7e4857a93247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lzaaerIsz7gS"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TzuSunNetwork(nn.Module):\n",
    "    def __init__(self, observation_shape, action_shape):\n",
    "        super(TzuSunNetwork, self).__init__()\n",
    "\n",
    "        height, width, channels = observation_shape\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.Conv2d(channels, observation_shape[-1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(observation_shape[-1]),\n",
    "            nn.Conv2d(observation_shape[-1], observation_shape[-1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(observation_shape[-1]),\n",
    "            nn.Conv2d(observation_shape[-1], observation_shape[-1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Calculate flattened size after CNN\n",
    "        flattened_size = observation_shape[-1] * height * width\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)  # Change from (1, 13, 13, 5) to (1, 5, 13, 13)\n",
    "        x = self.cnn(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "v4sRg4IJDzAz",
    "outputId": "6a5079a6-3556-4ad8-981c-3d8a345fe5c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import deque, namedtuple\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from magent2.environments import battle_v4\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "env = battle_v4.env(map_size=45, minimap_mode=False, step_reward=0.001,\n",
    "                        dead_penalty=-1, attack_penalty=-0.01, attack_opponent_reward=1,\n",
    "                        max_cycles=200, extra_features=False, render_mode=\"rgb_array\")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 10\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "observation_shape = env.observation_space(\"blue_0\").shape\n",
    "action_shape = env.action_space(\"blue_0\").n\n",
    "\n",
    "policy_net = TzuSunNetwork(observation_shape, action_shape).to(device)\n",
    "target_net = TzuSunNetwork(observation_shape, action_shape).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "episode_rewards = []\n",
    "episode_losses = []\n",
    "running_loss = 0.0\n",
    "\n",
    "def select_action(observation):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(observation).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space(\"blue_0\").sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 5 episode averages and plot them too\n",
    "    if len(durations_t) >= 5:\n",
    "        means = durations_t.unfold(0, 5, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(4), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    global running_loss\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "num_episodes = 20\n",
    "\n",
    "try:\n",
    "    for i_episode in range(num_episodes):\n",
    "        # Initialize the environment and get its state\n",
    "        env.reset()\n",
    "        episode_reward = 0\n",
    "        running_loss = 0.0\n",
    "        steps_done += 1\n",
    "\n",
    "        for agent in env.agent_iter():\n",
    "\n",
    "            observation, reward, termination, truncation, info = env.last()\n",
    "            observation = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            done = termination or truncation\n",
    "\n",
    "            if done:\n",
    "                action = None  # Agent is dead\n",
    "                env.step(action)\n",
    "            else:\n",
    "                agent_handle = agent.split(\"_\")[0]\n",
    "                if agent_handle == \"blue\":\n",
    "\n",
    "                    action = select_action(observation)\n",
    "\n",
    "                    observation, reward, terminated, truncated, info = env.last()\n",
    "                    observation = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                    env.step(action.item())\n",
    "\n",
    "                    next_observation, reward, termination, truncation, info = env.last()\n",
    "                    next_observation = torch.tensor(next_observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                    reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "\n",
    "                    # Store the transition in memory\n",
    "                    memory.push(observation, action, next_observation, reward)\n",
    "\n",
    "                    # Move to the next state\n",
    "                    observation = next_observation\n",
    "\n",
    "                    # Perform one step of the optimization (on the policy network)\n",
    "                    optimize_model()\n",
    "\n",
    "                    # Soft update of the target network's weights\n",
    "                    # θ′ ← τ θ + (1 −τ )θ′\n",
    "                    target_net_state_dict = target_net.state_dict()\n",
    "                    policy_net_state_dict = policy_net.state_dict()\n",
    "                    for key in policy_net_state_dict:\n",
    "                        target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "                    target_net.load_state_dict(target_net_state_dict)\n",
    "                else:\n",
    "                    # red agent (random)\n",
    "                    action = env.action_space(\"red_0\").sample()\n",
    "                    env.step(action)\n",
    "\n",
    "            # Update episode reward\n",
    "            episode_reward += reward\n",
    "\n",
    "        # Add these lines at the end of each episode\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_losses.append(running_loss)\n",
    "\n",
    "        print(f'Episode {i_episode + 1}/{num_episodes}')\n",
    "        print(f'Total Reward: {episode_reward.item():.2f}')\n",
    "        print(f'Average Loss: {running_loss:.4f}')\n",
    "        print(f'Epsilon: {EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY):.2f}')\n",
    "        print('-' * 40)\n",
    "\n",
    "        # Plot after each episode\n",
    "        plot_durations()\n",
    "    torch.save({\n",
    "        'episode': i_episode,\n",
    "        'policy_net_state_dict': policy_net.state_dict(),\n",
    "        'target_net_state_dict': target_net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'episode_losses': episode_losses,\n",
    "    }, \"models/blue.pt\")\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')\n",
    "    torch.save({\n",
    "        'episode': i_episode,\n",
    "        'policy_net_state_dict': policy_net.state_dict(),\n",
    "        'target_net_state_dict': target_net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'episode_losses': episode_losses,\n",
    "    }, \"models/blue.pt\")\n",
    "finally:\n",
    "    print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
